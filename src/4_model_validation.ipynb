{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d5403f0-6d34-4920-a29b-e5ca7588fc4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet mlflow==2.22.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "820cb7d6-2bb6-475a-a654-27bc14f4a87b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37af6fc7-e2d8-4a51-86e3-ec3a4a9e93ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\", \"mlops\")\n",
    "dbutils.widgets.text(\"schema\", \"mlops_zoomcamp_prj\")\n",
    "dbutils.widgets.text(\"model_name\", \"software_defects\")\n",
    "\n",
    "model = dbutils.widgets.get(\"model_name\")\n",
    "# dbutils.widgets.text(\"experiment_name\", \"software-defects\")\n",
    "\n",
    "# experiment_name = dbutils.widgets.get(\"experiment_name\")\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "db = dbutils.widgets.get(\"schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a98f2c-47be-4b3e-b770-43e555049062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n",
    "\n",
    "\n",
    "requirements_path = ModelsArtifactRepository(f\"models:/{catalog}.{db}.{model}@candidate\").download_artifacts(artifact_path=\"requirements.txt\") # download model from remote registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "705afdf4-4981-4305-af62-12aeeab72544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "catalog": "mlops",
        "model_name": "software_defects_prediction",
        "schema": "mlops_zoomcamp_prj"
       },
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %pip install --quiet -r $requirements_path\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e41dbe9-8a55-43b4-9931-52893ca08164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b17395-e3f3-4e9d-80b8-3fcc425ee278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating candidate model for mlops.mlops_zoomcamp_prj.software_defects on model version 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We are interested in validating the candidate model\n",
    "model_alias = \"candidate\"\n",
    "model_name = f\"{catalog}.{db}.{model}\"\n",
    "\n",
    "model_details = client.get_model_version_by_alias(model_name, model_alias)\n",
    "model_version = int(model_details.version)\n",
    "\n",
    "print(f\"Validating {model_alias} model for {model_name} on model version {model_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d0295b4-3343-44b5-a17a-38cbbe086229",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Check candidate model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3be95dc3-6740-4bdb-83a5-c624bd6fdef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mlops.mlops_zoomcamp_prj.software_defects version 1 has description: True\n"
     ]
    }
   ],
   "source": [
    "# If there's no description or an insufficient number of characters, tag accordingly\n",
    "if not model_details.description:\n",
    "  has_description = False\n",
    "  print(\"Please add model description\")\n",
    "elif not len(model_details.description) > 20:\n",
    "  has_description = False\n",
    "  print(\"Please add detailed model description (40 char min).\")\n",
    "else:\n",
    "  has_description = True\n",
    "\n",
    "print(f'Model {model_name} version {model_details.version} has description: {has_description}')\n",
    "client.set_model_version_tag(name=model_name, version=str(model_details.version), key=\"has_description\", value=has_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e965cc9d-4917-4e73-867c-e976529d4d72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Checks candidate model against Production model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f4d9f61-f233-4ec5-975c-0c41f71cacc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No production found. Accept the model as it's the first one.\nModel mlops.mlops_zoomcamp_prj.software_defects version 1 metric_accuracy_passed: True\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy score against Prod model\n",
    "model_run_id = model_details.run_id\n",
    "accuracy_score = mlflow.get_run(model_run_id).data.metrics['accuracy']\n",
    "\n",
    "try:\n",
    "    #Compare the candidate accuracy score to the existing champion if it exists\n",
    "    production_model = client.get_model_version_by_alias(model_name, \"production\")\n",
    "    production_accuracy = mlflow.get_run(production_model.run_id).data.metrics['test_accuracy_score']\n",
    "    print(f'production accuracy score: {production_accuracy}. candidate accuracy score: {accuracy_score}.')\n",
    "    metric_accuracy_passed = accuracy_score >= production_accuracy\n",
    "except:\n",
    "    print(f\"No production found. Accept the model as it's the first one.\")\n",
    "    metric_accuracy_passed = True\n",
    "\n",
    "print(f'Model {model_name} version {model_details.version} metric_accuracy_passed: {metric_accuracy_passed}')\n",
    "# Tag that accuracy metric check has passed\n",
    "client.set_model_version_tag(name=model_name, version=model_details.version, key=\"metric_accuracy_passed\", value=metric_accuracy_passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "457ad49f-d80d-4a05-9571-9a8f0eeaa801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Promote candidate model to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a0ea6a-06c6-428c-93f4-c57f2c3e354a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'accuracy': '0.8967',\n",
       " 'has_description': 'True',\n",
       " 'metric_accuracy_passed': 'True'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = client.get_model_version(model_name, model_version)\n",
    "results.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f78eae-a750-46ca-ba98-160cfea33540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register model as production!\n"
     ]
    }
   ],
   "source": [
    "if results.tags[\"has_description\"] == \"True\" and results.tags[\"metric_accuracy_passed\"] == \"True\":\n",
    "  print('register model as production!')\n",
    "  client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"production\",\n",
    "    version=model_version\n",
    "  )\n",
    "\n",
    "  client.delete_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"candidate\"    \n",
    "  )\n",
    "else:\n",
    "  raise Exception(\"Model not ready for promotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "206f4435-89a9-4a90-9af8-da28a1aff126",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "catalog": "mlops",
        "model_name": "software_defects_prediction",
        "schema": "mlops_zoomcamp_prj"
       },
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pyspark.sql.functions as F\n",
    "# #get our validation dataset:\n",
    "# validation_df = spark.table('mlops.mlops_zoomcamp_prj.soft_quality_features').filter(\"split='validate'\")\n",
    "\n",
    "# #Call the model with the given alias and return the prediction\n",
    "# def predict_defects(validation_df, model_alias):\n",
    "#     model = mlflow.pyfunc.spark_udf(spark, model_uri=f\"models:/{catalog}.{db}.{model}@{model_alias}\") #Use env_manager=\"virtualenv\" to recreate a venv with the same python version if needed\n",
    "#     return validation_df.withColumn('predictions', model(*model.metadata.get_input_schema().input_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d763c1c5-da3e-42a0-8f04-6124bdbb25f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 10:55:04,821 14567 ERROR _handle_rpc_error GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\", line 1535, in _analyze\n    resp = self._stub.AnalyzePlan(req, metadata=self.metadata())\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n                             ^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n           ^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_channel.py\", line 440, in result\n    raise self\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_channel.py\", line 1198, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"[TABLE_OR_VIEW_NOT_FOUND] The table or view `mlops_churn_inference` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01;\n'UnresolvedRelation [mlops_churn_inference], [], false\n\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `mlops_churn_inference` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01;\\n\\'UnresolvedRelation [mlops_churn_inference], [], false\\n\", grpc_status:13, created_time:\"2025-07-12T10:55:04.820223437+00:00\"}\"\n>\n2025-07-12 10:55:04,821 14567 ERROR _handle_rpc_error GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\", line 1535, in _analyze\n    resp = self._stub.AnalyzePlan(req, metadata=self.metadata())\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n                             ^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n           ^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_channel.py\", line 440, in result\n    raise self\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_channel.py\", line 1198, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.11/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"[TABLE_OR_VIEW_NOT_FOUND] The table or view `mlops_churn_inference` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01;\n'UnresolvedRelation [mlops_churn_inference], [], false\n\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `mlops_churn_inference` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01;\\n\\'UnresolvedRelation [mlops_churn_inference], [], false\\n\", grpc_status:13, created_time:\"2025-07-12T10:55:04.820223437+00:00\"}\"\n>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mRestException\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-7112813776620545>, line 4\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m inference_df \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mtable(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlops_churn_inference\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Load champion model as a Spark UDF. You can use virtual env manager for the demo to avoid version conflict (you can remove the pip install above with virtual env)\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m champion_model \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39mspark_udf(spark, model_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcatalog\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdb\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.mlops_churn@Champion\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m#Use env_manager=\"virtualenv\" to recreate a venv with the same python version if needed\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Batch score\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m preds_df \u001B[38;5;241m=\u001B[39m inference_df\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredictions\u001B[39m\u001B[38;5;124m'\u001B[39m, champion_model(\u001B[38;5;241m*\u001B[39mchampion_model\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mget_input_schema()\u001B[38;5;241m.\u001B[39minput_names()))\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_spark_udf.py:39\u001B[0m, in \u001B[0;36mapply_spark_udf_patch.<locals>.patch_init.<locals>.patched_spark_udf\u001B[0;34m(spark, model_uri, result_type, env_manager, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     37\u001B[0m loggable_tags \u001B[38;5;241m=\u001B[39m {}\n",
       "\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_spark_udf(\n",
       "\u001B[1;32m     40\u001B[0m         spark,\n",
       "\u001B[1;32m     41\u001B[0m         model_uri,\n",
       "\u001B[1;32m     42\u001B[0m         result_type,\n",
       "\u001B[1;32m     43\u001B[0m         env_manager,\n",
       "\u001B[1;32m     44\u001B[0m         \u001B[38;5;241m*\u001B[39margs,\n",
       "\u001B[1;32m     45\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n",
       "\u001B[1;32m     46\u001B[0m     )\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m     48\u001B[0m     exception \u001B[38;5;241m=\u001B[39m e\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:2266\u001B[0m, in \u001B[0;36mspark_udf\u001B[0;34m(spark, model_uri, result_type, env_manager, params, extra_env, prebuilt_env_uri, model_config)\u001B[0m\n",
       "\u001B[1;32m   2256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m   2257\u001B[0m     is_spark_connect\n",
       "\u001B[1;32m   2258\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dbconnect_mode\n",
       "\u001B[1;32m   2259\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m env_manager \u001B[38;5;129;01min\u001B[39;00m (_EnvManager\u001B[38;5;241m.\u001B[39mVIRTUALENV, _EnvManager\u001B[38;5;241m.\u001B[39mCONDA)\n",
       "\u001B[1;32m   2260\u001B[0m ):\n",
       "\u001B[1;32m   2261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\n",
       "\u001B[1;32m   2262\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnvironment manager \u001B[39m\u001B[38;5;132;01m{\u001B[39;00menv_manager\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m is not supported in Spark Connect \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   2263\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclient environment if it connects to non-Databricks Spark cluster.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   2264\u001B[0m     )\n",
       "\u001B[0;32m-> 2266\u001B[0m local_model_path \u001B[38;5;241m=\u001B[39m _download_artifact_from_uri(\n",
       "\u001B[1;32m   2267\u001B[0m     artifact_uri\u001B[38;5;241m=\u001B[39mmodel_uri,\n",
       "\u001B[1;32m   2268\u001B[0m     output_path\u001B[38;5;241m=\u001B[39m_create_model_downloading_tmp_dir(should_use_nfs),\n",
       "\u001B[1;32m   2269\u001B[0m )\n",
       "\u001B[1;32m   2271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prebuilt_env_uri:\n",
       "\u001B[1;32m   2272\u001B[0m     prebuilt_env_uri \u001B[38;5;241m=\u001B[39m _download_prebuilt_env_if_needed(prebuilt_env_uri)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/tracking/artifact_utils.py:108\u001B[0m, in \u001B[0;36m_download_artifact_from_uri\u001B[0;34m(artifact_uri, output_path, lineage_header_info)\u001B[0m\n",
       "\u001B[1;32m    100\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    101\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n",
       "\u001B[1;32m    102\u001B[0m \u001B[38;5;124;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    lineage_header_info: The model lineage header info to be consumed by lineage services.\u001B[39;00m\n",
       "\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    107\u001B[0m root_uri, artifact_path \u001B[38;5;241m=\u001B[39m _get_root_uri_and_artifact_path(artifact_uri)\n",
       "\u001B[0;32m--> 108\u001B[0m repo \u001B[38;5;241m=\u001B[39m get_artifact_repository(artifact_uri\u001B[38;5;241m=\u001B[39mroot_uri)\n",
       "\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(repo, ModelsArtifactRepository):\n",
       "\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m repo\u001B[38;5;241m.\u001B[39mdownload_artifacts(\n",
       "\u001B[1;32m    112\u001B[0m         artifact_path\u001B[38;5;241m=\u001B[39martifact_path,\n",
       "\u001B[1;32m    113\u001B[0m         dst_path\u001B[38;5;241m=\u001B[39moutput_path,\n",
       "\u001B[1;32m    114\u001B[0m         lineage_header_info\u001B[38;5;241m=\u001B[39mlineage_header_info,\n",
       "\u001B[1;32m    115\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:133\u001B[0m, in \u001B[0;36mget_artifact_repository\u001B[0;34m(artifact_uri)\u001B[0m\n",
       "\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_artifact_repository\u001B[39m(artifact_uri: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ArtifactRepository:\n",
       "\u001B[1;32m    121\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001B[39;00m\n",
       "\u001B[1;32m    123\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m        requirements.\u001B[39;00m\n",
       "\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _artifact_repository_registry\u001B[38;5;241m.\u001B[39mget_artifact_repository(artifact_uri)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:77\u001B[0m, in \u001B[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001B[0;34m(self, artifact_uri)\u001B[0m\n",
       "\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repository \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n",
       "\u001B[1;32m     74\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find a registered artifact repository for: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00martifact_uri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m     75\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrently registered schemes are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m     76\u001B[0m     )\n",
       "\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m repository(artifact_uri)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:48\u001B[0m, in \u001B[0;36mModelsArtifactRepository.__init__\u001B[0;34m(self, artifact_uri)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m registry_uri \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mget_registry_uri()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_databricks_unity_catalog_uri(uri\u001B[38;5;241m=\u001B[39mregistry_uri):\n",
       "\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m UnityCatalogModelsArtifactRepository(\n",
       "\u001B[1;32m     49\u001B[0m         artifact_uri\u001B[38;5;241m=\u001B[39martifact_uri, registry_uri\u001B[38;5;241m=\u001B[39mregistry_uri\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39mmodel_name\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39mmodel_version\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/unity_catalog_models_artifact_repo.py:92\u001B[0m, in \u001B[0;36mUnityCatalogModelsArtifactRepository.__init__\u001B[0;34m(self, artifact_uri, registry_uri)\u001B[0m\n",
       "\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
       "\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
       "\u001B[0;32m---> 92\u001B[0m model_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_version \u001B[38;5;241m=\u001B[39m get_model_name_and_version(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient, artifact_uri)\n",
       "\u001B[1;32m     93\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name \u001B[38;5;241m=\u001B[39m get_full_name_from_sc(model_name, spark)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/utils/models.py:97\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[0;34m(client, models_uri)\u001B[0m\n",
       "\u001B[1;32m     94\u001B[0m     client \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39m_get_registry_client()\n",
       "\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m---> 97\u001B[0m     mv \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\n",
       "\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, mv\u001B[38;5;241m.\u001B[39mversion\n",
       "\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_name, \u001B[38;5;28mstr\u001B[39m(_get_latest_model_version(client, model_name, model_stage))\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/tracking/_model_registry/client.py:433\u001B[0m, in \u001B[0;36mModelRegistryClient.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n",
       "\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model_version_by_alias\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, alias):\n",
       "\u001B[1;32m    423\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n",
       "\u001B[1;32m    424\u001B[0m \n",
       "\u001B[1;32m    425\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    431\u001B[0m \n",
       "\u001B[1;32m    432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(name, alias)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:1038\u001B[0m, in \u001B[0;36mUcModelRegistryStore.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n",
       "\u001B[1;32m   1036\u001B[0m full_name \u001B[38;5;241m=\u001B[39m get_full_name_from_sc(name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspark)\n",
       "\u001B[1;32m   1037\u001B[0m req_body \u001B[38;5;241m=\u001B[39m message_to_json(GetModelVersionByAliasRequest(name\u001B[38;5;241m=\u001B[39mfull_name, alias\u001B[38;5;241m=\u001B[39malias))\n",
       "\u001B[0;32m-> 1038\u001B[0m response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(GetModelVersionByAliasRequest, req_body)\n",
       "\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_version_from_uc_proto(response_proto\u001B[38;5;241m.\u001B[39mmodel_version)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/model_registry/base_rest_store.py:44\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n",
       "\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m     43\u001B[0m     endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n",
       "\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n",
       "\u001B[1;32m     45\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n",
       "\u001B[1;32m     46\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:402\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001B[0m\n",
       "\u001B[1;32m    399\u001B[0m     call_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m json_body\n",
       "\u001B[1;32m    400\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n",
       "\u001B[0;32m--> 402\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n",
       "\u001B[1;32m    403\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n",
       "\u001B[1;32m    404\u001B[0m js_dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response_to_parse)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:259\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n",
       "\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
       "\u001B[1;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n",
       "\u001B[0;32m--> 259\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n",
       "\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    261\u001B[0m         base_msg \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m    262\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    263\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m != 200\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    264\u001B[0m         )\n",
       "\n",
       "\u001B[0;31mRestException\u001B[0m: RESOURCE_DOES_NOT_EXIST: Routine or Model 'mlops.mlops_zoomcamp_prj.mlops_churn' does not exist."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "RestException",
        "evalue": "RESOURCE_DOES_NOT_EXIST: Routine or Model 'mlops.mlops_zoomcamp_prj.mlops_churn' does not exist."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>RestException</span>: RESOURCE_DOES_NOT_EXIST: Routine or Model 'mlops.mlops_zoomcamp_prj.mlops_churn' does not exist."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mRestException\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m<command-7112813776620545>, line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m inference_df \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mtable(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlops_churn_inference\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Load champion model as a Spark UDF. You can use virtual env manager for the demo to avoid version conflict (you can remove the pip install above with virtual env)\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m champion_model \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39mspark_udf(spark, model_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcatalog\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdb\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.mlops_churn@Champion\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m#Use env_manager=\"virtualenv\" to recreate a venv with the same python version if needed\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Batch score\u001B[39;00m\n\u001B[1;32m      7\u001B[0m preds_df \u001B[38;5;241m=\u001B[39m inference_df\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredictions\u001B[39m\u001B[38;5;124m'\u001B[39m, champion_model(\u001B[38;5;241m*\u001B[39mchampion_model\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mget_input_schema()\u001B[38;5;241m.\u001B[39minput_names()))\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_spark_udf.py:39\u001B[0m, in \u001B[0;36mapply_spark_udf_patch.<locals>.patch_init.<locals>.patched_spark_udf\u001B[0;34m(spark, model_uri, result_type, env_manager, *args, **kwargs)\u001B[0m\n\u001B[1;32m     37\u001B[0m loggable_tags \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_spark_udf(\n\u001B[1;32m     40\u001B[0m         spark,\n\u001B[1;32m     41\u001B[0m         model_uri,\n\u001B[1;32m     42\u001B[0m         result_type,\n\u001B[1;32m     43\u001B[0m         env_manager,\n\u001B[1;32m     44\u001B[0m         \u001B[38;5;241m*\u001B[39margs,\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m     46\u001B[0m     )\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     48\u001B[0m     exception \u001B[38;5;241m=\u001B[39m e\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:2266\u001B[0m, in \u001B[0;36mspark_udf\u001B[0;34m(spark, model_uri, result_type, env_manager, params, extra_env, prebuilt_env_uri, model_config)\u001B[0m\n\u001B[1;32m   2256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2257\u001B[0m     is_spark_connect\n\u001B[1;32m   2258\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dbconnect_mode\n\u001B[1;32m   2259\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m env_manager \u001B[38;5;129;01min\u001B[39;00m (_EnvManager\u001B[38;5;241m.\u001B[39mVIRTUALENV, _EnvManager\u001B[38;5;241m.\u001B[39mCONDA)\n\u001B[1;32m   2260\u001B[0m ):\n\u001B[1;32m   2261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\n\u001B[1;32m   2262\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnvironment manager \u001B[39m\u001B[38;5;132;01m{\u001B[39;00menv_manager\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m is not supported in Spark Connect \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2263\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclient environment if it connects to non-Databricks Spark cluster.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2264\u001B[0m     )\n\u001B[0;32m-> 2266\u001B[0m local_model_path \u001B[38;5;241m=\u001B[39m _download_artifact_from_uri(\n\u001B[1;32m   2267\u001B[0m     artifact_uri\u001B[38;5;241m=\u001B[39mmodel_uri,\n\u001B[1;32m   2268\u001B[0m     output_path\u001B[38;5;241m=\u001B[39m_create_model_downloading_tmp_dir(should_use_nfs),\n\u001B[1;32m   2269\u001B[0m )\n\u001B[1;32m   2271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prebuilt_env_uri:\n\u001B[1;32m   2272\u001B[0m     prebuilt_env_uri \u001B[38;5;241m=\u001B[39m _download_prebuilt_env_if_needed(prebuilt_env_uri)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/tracking/artifact_utils.py:108\u001B[0m, in \u001B[0;36m_download_artifact_from_uri\u001B[0;34m(artifact_uri, output_path, lineage_header_info)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;124;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    lineage_header_info: The model lineage header info to be consumed by lineage services.\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    107\u001B[0m root_uri, artifact_path \u001B[38;5;241m=\u001B[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001B[0;32m--> 108\u001B[0m repo \u001B[38;5;241m=\u001B[39m get_artifact_repository(artifact_uri\u001B[38;5;241m=\u001B[39mroot_uri)\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(repo, ModelsArtifactRepository):\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m repo\u001B[38;5;241m.\u001B[39mdownload_artifacts(\n\u001B[1;32m    112\u001B[0m         artifact_path\u001B[38;5;241m=\u001B[39martifact_path,\n\u001B[1;32m    113\u001B[0m         dst_path\u001B[38;5;241m=\u001B[39moutput_path,\n\u001B[1;32m    114\u001B[0m         lineage_header_info\u001B[38;5;241m=\u001B[39mlineage_header_info,\n\u001B[1;32m    115\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:133\u001B[0m, in \u001B[0;36mget_artifact_repository\u001B[0;34m(artifact_uri)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_artifact_repository\u001B[39m(artifact_uri: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ArtifactRepository:\n\u001B[1;32m    121\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m        requirements.\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _artifact_repository_registry\u001B[38;5;241m.\u001B[39mget_artifact_repository(artifact_uri)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:77\u001B[0m, in \u001B[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repository \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m     74\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find a registered artifact repository for: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00martifact_uri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     75\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrently registered schemes are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     76\u001B[0m     )\n\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m repository(artifact_uri)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:48\u001B[0m, in \u001B[0;36mModelsArtifactRepository.__init__\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     46\u001B[0m registry_uri \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mget_registry_uri()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_databricks_unity_catalog_uri(uri\u001B[38;5;241m=\u001B[39mregistry_uri):\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m UnityCatalogModelsArtifactRepository(\n\u001B[1;32m     49\u001B[0m         artifact_uri\u001B[38;5;241m=\u001B[39martifact_uri, registry_uri\u001B[38;5;241m=\u001B[39mregistry_uri\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39mmodel_name\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39mmodel_version\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/unity_catalog_models_artifact_repo.py:92\u001B[0m, in \u001B[0;36mUnityCatalogModelsArtifactRepository.__init__\u001B[0;34m(self, artifact_uri, registry_uri)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m---> 92\u001B[0m model_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_version \u001B[38;5;241m=\u001B[39m get_model_name_and_version(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient, artifact_uri)\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name \u001B[38;5;241m=\u001B[39m get_full_name_from_sc(model_name, spark)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/artifact/utils/models.py:97\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[0;34m(client, models_uri)\u001B[0m\n\u001B[1;32m     94\u001B[0m     client \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39m_get_registry_client()\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m     mv \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, mv\u001B[38;5;241m.\u001B[39mversion\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_name, \u001B[38;5;28mstr\u001B[39m(_get_latest_model_version(client, model_name, model_stage))\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/tracking/_model_registry/client.py:433\u001B[0m, in \u001B[0;36mModelRegistryClient.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model_version_by_alias\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, alias):\n\u001B[1;32m    423\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n\u001B[1;32m    424\u001B[0m \n\u001B[1;32m    425\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    431\u001B[0m \n\u001B[1;32m    432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(name, alias)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:1038\u001B[0m, in \u001B[0;36mUcModelRegistryStore.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n\u001B[1;32m   1036\u001B[0m full_name \u001B[38;5;241m=\u001B[39m get_full_name_from_sc(name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspark)\n\u001B[1;32m   1037\u001B[0m req_body \u001B[38;5;241m=\u001B[39m message_to_json(GetModelVersionByAliasRequest(name\u001B[38;5;241m=\u001B[39mfull_name, alias\u001B[38;5;241m=\u001B[39malias))\n\u001B[0;32m-> 1038\u001B[0m response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(GetModelVersionByAliasRequest, req_body)\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_version_from_uc_proto(response_proto\u001B[38;5;241m.\u001B[39mmodel_version)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/store/model_registry/base_rest_store.py:44\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m     endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n\u001B[1;32m     46\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:402\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001B[0m\n\u001B[1;32m    399\u001B[0m     call_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m json_body\n\u001B[1;32m    400\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n\u001B[0;32m--> 402\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n\u001B[1;32m    403\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n\u001B[1;32m    404\u001B[0m js_dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response_to_parse)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d96a5dbb-3c24-467c-a771-233c1171d51b/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:259\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n\u001B[0;32m--> 259\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    261\u001B[0m         base_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    262\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    263\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m != 200\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    264\u001B[0m         )\n",
        "\u001B[0;31mRestException\u001B[0m: RESOURCE_DOES_NOT_EXIST: Routine or Model 'mlops.mlops_zoomcamp_prj.mlops_churn' does not exist."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Load customer features to be scored\n",
    "# inference_df = spark.read.table(f\"mlops_churn_inference\")\n",
    "# # Load champion model as a Spark UDF. You can use virtual env manager for the demo to avoid version conflict (you can remove the pip install above with virtual env)\n",
    "# champion_model = mlflow.pyfunc.spark_udf(spark, model_uri=f\"models:/{catalog}.{db}.mlops_churn@Champion\") #Use env_manager=\"virtualenv\" to recreate a venv with the same python version if needed\n",
    "\n",
    "# # Batch score\n",
    "# preds_df = inference_df.withColumn('predictions', champion_model(*champion_model.metadata.get_input_schema().input_names()))\n",
    "\n",
    "# display(preds_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7872475937595132,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "4_model_validation",
   "widgets": {
    "catalog": {
     "currentValue": "mlops",
     "nuid": "98d78390-2c1c-4ba2-b3d9-26e363f9e11f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "mlops",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "mlops",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_name": {
     "currentValue": "software_defects",
     "nuid": "d48a8d2c-d24c-405c-a98c-0538564fcd39",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "software_defects",
      "label": null,
      "name": "model_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "software_defects",
      "label": null,
      "name": "model_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "mlops_zoomcamp_prj",
     "nuid": "dc7ddfb5-0496-4b45-8d9b-8cd563d970e2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "mlops_zoomcamp_prj",
      "label": null,
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "mlops_zoomcamp_prj",
      "label": null,
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}